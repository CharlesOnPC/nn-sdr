import pandas as pd
import random
import numpy
import numpy as np
from decimal import Decimal

def relu(x):
    return np.maximum(0,x)

def softmax(x):
    e_x = np.exp(x-np.max(x))
    return e_x / e_x.sum(axis=len(x.shape)-1,keepdims=True)

def softmax_derivative(x,position):
    x = x-np.max(x)
    e_x = np.exp(x[position-1])
    e_x_sum = 0
    for i in x:
        e_x_sum += np.exp(i)
    sum = e_x / e_x_sum
    return sum*(1-sum)

def error_derivative(error,predicted):
    return predicted-error


# Import ASK2 Test Set Generated by MATLAB
ask2_test_data = pd.read_excel("ask2_test_data.xls",header=None)

# Import ASK4 Test Set Generated by MATLAB
ask4_test_data = pd.read_excel("ask4_test_data.xls",header=None)

# Import FSK2 Test Set Generated by MATLAB
fsk2_test_data = pd.read_excel("fsk2_test_data.xls",header=None)

# Import FSK4 Test Set Generated by MATLAB
fsk4_test_data = pd.read_excel("fsk4_test_data.xls",header=None)

# Import PSK2 Test Set Generated by MATLAB
psk2_test_data = pd.read_excel("psk2_test_data.xls",header=None)

# Import PSK4 Test Set Generated by MATLAB
psk4_test_data = pd.read_excel("psk4_test_data.xls",header=None)

######## ASK2 ########

# Scale the first column down
ask2_test_data.iloc[:,1] = ask2_test_data.iloc[:,1]/100000000

# Slice the first 200 samples of the test set for ASK2 for training
ask2_test_set = ask2_test_data.iloc[0:199,:]

# Slice the next 100 samples of the test set for ASK2 validation on MLP
ask2_validation_set = ask2_test_data.iloc[200:299,:]



######## ASK4 ########
# Slice the first 200 samples of the test set for ASK4 for training
ask4_test_set = ask4_test_data.iloc[0:199,:]

# Slice the next 100 samples of the test set for ASK4 validation on MLP
ask4_validation_set = ask4_test_data.iloc[200:299,:]

######## FSK2 ########
# Slice the first 200 samples of the test set for FSK2 for training
fsk2_test_set = fsk2_test_data.iloc[0:199,:]

# Slice the next 100 samples of the test set for FSK2 validation on MLP
fsk2_validation_set = fsk2_test_data.iloc[200:299,:]

######## FSK4 ########
# Slice the first 200 samples of the test set for FSK4 for training
fsk4_test_set = fsk4_test_data.iloc[0:199,:]

# Slice the next 100 samples of the test set for ASK4 validation on MLP
fsk4_validation_set = fsk4_test_data.iloc[200:299,:]

######## PSK2 ########
# Slice the first 200 samples of the test set for PSK2 for training
psk2_test_set = psk2_test_data.iloc[0:199,:]

# Slice the next 100 samples of the test set for PSK2 validation on MLP
psk2_validation_set = psk2_test_data.iloc[200:299,:]

######## PSK4 ########
psk4_test_set = psk4_test_data.iloc[0:199,:]

psk4_validation_set = psk4_test_data.iloc[200:299,:]

######## Array with all Modulation Forms ########
test_set = numpy.zeros((6*200,6))

test_set[0:199]   = ask2_test_set.iloc[0:199,:]
test_set[200:399] = ask4_test_set.iloc[0:199,:]
test_set[400:599] = fsk2_test_set.iloc[0:199,:]
test_set[600:799] = fsk4_test_set.iloc[0:199,:]
test_set[800:999] = psk2_test_set.iloc[0:199,:]
test_set[1000:1199] = psk4_test_set.iloc[0:199,:]

# Declare number of features #
features = 5

# The MLP wil have one hidden layer with 8 nodes
number_of_nodes = 8

# Declare array for weight matrix of input layer to hidden layer
weight_array_l1  = numpy.zeros((number_of_nodes,features))

# Declare array for weight matrix of hidden layer to output layer
weight_array_l2  = numpy.zeros((number_of_nodes,features+1))

# Establish array for bias terms for each node in hidden layer
neurons_bias_term  = numpy.zeros((1,8))

output_layer = numpy.zeros((1,5))

# Choose random weight values to start
weight_array_l1 = np.random.randn(number_of_nodes,features)
weight_array_l2 = np.random.randn(number_of_nodes,features+1)

learning_rate = 0.1
epochs = 500

for epoch in range (0,epochs):
    print('On epoch number , ',epoch)
    for k in range(0,test_set.shape[0]):

        # Forward Pass starting with first data set
        z1 = numpy.dot(weight_array_l1,test_set[k,:-1],)

        # Apply Activation Function
        h1 = relu(z1)

        z2 = numpy.dot(h1.transpose(),weight_array_l2)


        output = softmax(z2)

        # Debug Print Test Set
        #print(test_set)

        # Get index of position of classification
        index = test_set[k,-1]

        index = int(index)

        # Create matrix with expected value
        expected_output = numpy.zeros((1,6))

        expected_output[0,index-1] = 1


        # Compute the error value
        error = (1/2)*np.square(np.subtract(expected_output,output))

        # New weight matrix
        new_weight_array_l1  = numpy.zeros((number_of_nodes,features))
        new_weight_array_l2  = numpy.zeros((number_of_nodes,features+1))

        for i in range(0,number_of_nodes):
            for j in range(0,features):
                weight_array_l1[i][j] = weight_array_l1[i][j] - (learning_rate * (error_derivative(expected_output[0,index-1],output[index-1])* softmax_derivative(z2,index-1)*h1.transpose()[i]*np.heaviside(h1[i],0.5)*test_set[k,j]))
                weight_array_l2[i][j] = weight_array_l2[i][j] - (learning_rate * (error_derivative(expected_output[0,index-1],output[index-1])* softmax_derivative(z2,index-1)*h1.transpose()[i]*np.heaviside(h1[i],0.5)))
